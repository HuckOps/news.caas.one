# 了解kubernetes网络:入口

在这一系列的[第一篇文章](https://medium.com/google-cloud/understanding-kubernetes-networking-pods-7117dd28727)中，我描述了允许pods跨[kubernetes](https://kubernetes.io/)集群中的节点彼此连接的网络。[第二篇文章重点](https://medium.com/@betz.mark/understanding-kubernetes-networking-services-f0cb48e4cc82)在于服务网络如何为pods提供负载平衡，以便集群内的客户机能够与pod可靠地通信。而第三篇也就是最后一篇文章，我想在这些概念的基础上展示集群之外的客户机如何使用相同的服务网络连接到pods。出于各种原因，第三篇文章可能是这三篇中最复杂的，第一和第二篇文章介绍的概念是从以下内容中获得更多价值的先决条件。

首先，2017年刚从奥斯汀的[库比肯](http://events17.linuxfoundation.org/events/kubecon-and-cloudnativecon-north-america)回来的时候，我想起了一些我在本系列早些时候可能已经说得很清楚的事情。Kubernetes是一个[迅速成熟](https://venturebeat.com/2017/12/07/kubernetes-1-9-launches-to-guarantee-stability-for-key-features/)的平台。大部分架构是可插拔的，这包括网络。我在这里一直描述的是[谷歌Kubernetes引擎](https://cloud.google.com/kubernetes-engine)的默认实现。我还没有看到亚马逊的Elastic Kubernetes服务，但我认为它也将接近默认实现。在某种程度上，kubernetes有一个处理网络的“标准”方法，我认为这些帖子从基本方面描述了它。您必须从某个地方开始，当您开始考虑诸如[统一服务网格](https://buoyant.io/2017/05/24/a-service-mesh-for-kubernetes-part-x-the-service-mesh-api/)等替代方案时，掌握好这些概念将会有所帮助。话虽如此，我们还是谈谈入口吧。

![img](https://miro.medium.com/max/875/1*yjol6DXyAZVyFafOlMlCAQ.png)

# 路由不是负载平衡

在[上一篇文章](https://medium.com/@betz.mark/understanding-kubernetes-networking-services-f0cb48e4cc82)中，我们创建了一个带有几个pod的部署，以及一个分配了IP的服务，称为“集群IP”，用于发送pod的请求。我将从这个例子继续构建。回想一下，服务的集群IP `**10.3.241.152**`位于一个IP地址范围内，该范围与pod网络以及节点本身所在的网络是分离的。我把这个地址空间称为“服务网络”，尽管它几乎称不上这个名字，因为它没有连接的设备，并且完全由路由规则组成。在本例中，我们展示了kubernetes组件[kube-proxy](https://kubernetes.io/docs/reference/generated/kube-proxy/)与linux内核模块[netfilter](http://www.netfilter.org/)协作，如何实现这个网络，从而捕获并重新路由发送到集群IP的流量，从而将其发送到一个健康的pod。

![img](https://miro.medium.com/max/875/1*Ow5A6_zjjwdKkf2Yi1KgYw.png)



到目前为止，我们一直在讨论“连接”和“请求”，甚至是更模糊的“流量”，但要理解kubernetes ingress的工作原理，我们需要更具体一些。连接和请求在[OSI](https://en.wikipedia.org/wiki/OSI_model)第4层(tcp)或第7层(http、rpc等)上运行。Netfilter规则是路由规则，它们在第3层的IP数据包上运行。所有路由器，包括netfilter，都或多或少地根据数据包中包含的信息做出路由决策;一般来说，就是它从哪里来，要去哪里。因此，用第3层的术语来描述这种行为:到达节点的`**eth0**`接口的每个以`**10.3.241.152:80**`发送给服务的数据包都由netfilter处理，匹配为我们的服务建立的规则，并转发到一个健康pod的IP。

很明显，我们使用的任何允许外部客户机调用我们的pods的机制都必须使用相同的路由基础设施。也就是说，那些外部客户端最终必须调用集群IP和端口，因为这是到目前为止我们所讨论的所有机器的“前端”，这使得我们可以在任何给定时间不关心pod在何处运行。然而，目前还不清楚如何实现这一目标。服务的集群IP只能从节点的以太网接口访问。集群之外的任何东西都不知道如何处理这个范围内的地址。我们如何将流量从公开可见的IP端点转发到只有在数据包已经位于节点上时才能访问的IP ?

![img](https://miro.medium.com/max/875/1*skurXk737KHhzbXPbV-Xcg.png)

如果你试图提出一个解决方案，你可能做的事情之一是使用[iptables](http://ipset.netfilter.org/iptables.man.html)实用程序检查netfilter规则，如果你做了这件事，你可能会发现一些令人惊讶的事情：示例服务的规则并不局限于一个特定的来源网络。也就是说，任何到达节点以太网接口的目的地为`**10.3.241.152:80**`的数据包都将匹配并路由到pod。
所以我们能不能给客户端一个集群IP，或者给它分配一个友好的域名，然后添加一个路由来把这些包放到一个节点上?

如果你这样做，它会起成功的。客户端调用集群IP，数据包沿着一条路径向下到达一个节点，并被转发到一个pod。这时，你可能忍不住要欢呼了，但是这个解决方案存在一些严重的问题。首先，节点是短暂的，就像pods一样。它们不像pods那样短暂，但是可以迁移到新的vm，集群可以上下伸缩，等等。在第3层数据包上运行的路由器无法区分健康服务和不健康服务。他们希望这条路线的下一次飞跃是稳定的、可用的。在大多数情况下，如果节点变得不可达，路由就会中断，并在很长一段时间内保持中断状态。即使路由是持久的，也会让所有外部通信通过一个节点，这可能不是最优的。

无论我们如何引入客户机流量，我们都必须以一种不依赖于集群中任何单个节点的健康状况的方式来实现。如果没有路由器的一些主动管理(这正是kube-proxy在管理netfilter中的角色)，使用路由确实没有可靠的方法来实现这一点。将kubernetes的职责扩展到外部路由器的管理对设计人员来说可能没有多大意义，特别是考虑到我们已经有了经过验证的工具，可以将客户机流量分配到一组机器上。它们被称为负载平衡器，这就是kubernetes ingress的解决方案，它实际上可以持续工作。现在是时候爬出第三层的地下室，再次谈论连接了。

要使用负载平衡器将客户机流量分配到集群中的节点，我们需要客户机可以连接到的公共IP，还需要节点本身的地址，负载平衡器可以将请求转发到这些节点。由于上述原因，我们无法使用服务网络(集群IP)在网关路由器和节点之间轻松创建稳定的静态路由。唯一可用的其他地址位于节点的以太网接口所连接的网络上，在本例中为`**10.100.0.0/24**`。网关路由器已经知道如何将数据包发送到这些接口，并且从负载均衡器发送到路由器的连接将到达正确的位置。但是，如果客户端想要在端口80上连接到我们的服务，我们不能仅仅将数据包发送到节点接口上的端口。

![img](https://miro.medium.com/max/875/1*I03T4FnCjlPmHNXhao4arg.png)

失败的原因显而易见。在`**10.100.0.3:80**`上没有进程侦听(或者如果有进程侦听的是错误的进程)，我们希望拦截我们的请求并将其定向到pod的netfilter规则与目标地址不匹配。它们只匹配服务网络上`**10.3.241.152:80**`上的集群IP。因此，当这些包到达那个接口时，它们不能被传递，内核用econnreject响应它们。这给我们留下了一个难题:netfilter用于转发数据包的网络不容易从网关路由到节点，而容易路由的网络不是netfilter转发的网络。解决这个问题的方法是在这些网络之间建立一个桥梁，这正是kubernetes使用NodePort所做的。

# NodePort服务

我们在上一篇文章中创建的示例服务没有指定类型，因此使用默认类型`**ClusterIP**`。还有另外两种类型的服务可以添加额外的功能，接下来最重要的是类型`**NodePort**`。下面是作为NodePort服务的示例服务。

```
kind: Service
apiVersion: v1
metadata:
  name: service-test
spec:
  type: NodePort
  selector:
    app: service_test_pod
  ports:
  - port: 80
    targetPort: http
```



NodePort类型的服务是具有附加功能的集群IP服务:它可以在节点的IP地址以及服务网络上指定的集群IP上访问。实现此目的的方法非常简单:当kubernetes创建一个NodePort服务kube-proxy分配一个范围为30000-32767的端口，并在每个节点的`**eth0**`接口上打开这个端口(因此名为“NodePort”)。到此端口的连接被转发到服务的集群IP。如果我们创建上面的服务并运行`**kubectl get svc service-test**`，我们可以看到为它分配的NodePort。

```
$ kubectl get svc service-test
NAME           CLUSTER-IP     EXTERNAL-IP   PORT(S)           AGE
service-test   10.3.241.152   <none>        80:32213/TCP      1m
```



在这种情况下，我们的服务被分配到NodePort 32213。这意味着我们现在可以连接到示例集群中任意一个节点上的服务，地址是`**10.100.0.2:32213**`或`**10.100.0.3:32213**`，流量将被转发到该服务。有了这一部分，我们现在就有了一个完整的管道，用于平衡到集群中所有节点的外部客户机请求的负载。

![img](https://miro.medium.com/max/875/1*Uo_wGCIlFopJZbf6THu0OQ.png)

在上面的图中客户端连接到负载均衡器通过公共IP地址,负载平衡器选择一个节点和连接到`* * 10.100.0.3:32213 * *`,kube-proxy收到此连接,并将其转发到服务集群IP` * * 10.3.241.152:80 * *`,此时netfilter匹配规则,请求会被重定向到`* * 10.0.2.2:8080 * *`服务器吊舱。这看起来可能有点复杂，在某些方面确实如此，但是很难找到一个更直接的解决方案来维护pod和服务网络提供的所有功能。

这一机制并非没有问题。使用NodePorts将您的服务公开给非标准端口上的客户端。这通常不是问题，因为负载平衡器可以公开通常的端口，并向最终用户屏蔽节点端口。但是在某些场景中，比如在谷歌云上的内部负载平衡，您将被迫向上传播NodePort。节点也是一个有限的资源，尽管2768对于最大的集群来说可能已经足够了。对于大多数应用程序，可以让kubernetes随机选择端口，但如果需要，还可以显式地设置端口。最后，在请求中保存源ip存在一些限制。有关如何管理这些问题的信息，请参阅有关该主题的[文档文章](https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeclusterip)。

节点是所有外部通信进入kubernetes集群的基本机制。然而，它本身并不是一个完整的解决方案。由于上述原因，无论您的客户端是内部的还是通过公共网络进入的，您总是需要在集群前面安装某种负载平衡器。该平台的设计者认识到了这一点，并提供了两种不同的方法来从kubernetes内部指定负载平衡器配置，所以接下来让我们快速地看一下。

# LoadBalancer服务和Ingress资源

这两个概念是kubernetes执行的比较复杂的功能之一，但我不会在它们上面花太多时间，因为它们不会真正改变我们刚刚讨论的任何内容。如上所述，所有外部流量最终都通过NodePort进入集群。设计师本可以就此打住，让你只担心公共ip和负载平衡器，实际上在某些情况下，比如在裸金属上运行或者在你的家庭实验室中，这就是你必须要做的。但是在支持API驱动的网络资源配置的环境中，kubernetes可以在一个地方定义所有内容。

第一个也是最简单的方法是第三种kubernetes服务，称为LoadBalancer服务。类型为`**LoadBalancer**`的服务具有NodePort服务的所有功能，还可以构建完整的入口路径，假设您运行在支持API驱动的网络资源配置的环境中，比如GCP或AWS。

```
kind: Service
apiVersion: v1
metadata:
  name: service-test
spec:
  type: LoadBalancer
  selector:
    app: service_test_pod
  ports:
  - port: 80
    targetPort: http
```



如果我们删除并重新创建谷歌Kubernetes引擎上的示例服务，我们很快就可以看到，使用`**kubectl get svc service-test**`，已经分配了一个外部IP。

```
$ kubectl get svc service-test
NAME      CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE
openvpn   10.3.241.52     35.184.97.156   80:32213/TCP     5m
```



我说“很快”，尽管分配外部IP可能需要几分钟的时间，但考虑到必须调出的资源数量，这并不奇怪。例如，在GCP上，这要求系统创建一个外部IP、一个转发规则、一个目标代理、一个后端服务，可能还有一个实例组。一旦分配了IP，您就可以通过它连接到您的服务，为其分配一个域名并将其分发给客户端。只要服务没有被销毁和重新创建(很少有好的理由这样做)，IP就不会改变。

LoadBalancer类型的服务有一些限制。即无法将lb配置为终止https流量。您不能执行虚拟主机或基于路径的路由，因此不能使用单个负载平衡器以任何实际有用的方式代理到多个服务。这些限制导致在1.2版中添加了一个单独的kubernetes资源，用于配置负载平衡器，称为[Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/)。LoadBalancer服务都是关于扩展单个服务来支持外部客户端。相比之下，入口是一个单独的资源，可以更灵活地配置负载平衡器。Ingress API支持TLS终止、虚拟主机和基于路径的路由。它可以很容易地设置一个负载平衡器来处理多个后端服务。

Ingress API是一个太大的主题，不能在这里详细讨论，因为正如前面提到的，它与Ingress在网络级别上的实际工作关系不大。实现遵循一个基本的kubernetes模式:一个资源类型和一个控制器来管理该类型。本例中的资源是一个入口，它包含对网络资源的请求。下面是我们的测试服务的入口资源的样子。

```
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: test-ingress
  annotations:
    kubernetes.io/ingress.class: "gce"
spec:
  tls:
    - secretName: my-ssl-secret
  rules:
  - host: testhost.com
    http:
      paths:
      - path: /*
        backend:
          serviceName: service-test
          servicePort: 80
```



入口控制器负责通过将环境中的资源驱动到必要的状态来满足这个请求。当使用一个Ingress时，您将您的服务创建为NodePort类型，并让Ingress控制器找出如何获得节点的流量。有针对GCE负载平衡器、AWS弹性负载平衡器和流行代理(如nginx和haproxy)的入口控制器实现。注意，在某些环境中，将Ingress资源与LoadBalancer服务混合使用可能会导致一些微妙的问题。这些都可以很容易地解决，但是一般来说，即使是简单的服务，使用Ingress也可能是最好的。

# 主机端口和主机网络

这两者更多地属于有趣的新奇事物，而不是有用的工具。事实上，我觉得在实例中它们是99.99%的反模式，任何使用它们的实现都应该得到一个自动的设计审查。我考虑过把它们完全排除在外，但它们是某种进入的途径，所以很有必要简要地看一下它们的作用。

第一个是HostPort。这是容器的属性(在ContainerPort结构中声明)，当设置为给定的整数端口号时，将在节点上打开该端口并直接转发到容器。没有代理，端口只在容器运行的节点上打开。在添加[守护集](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)和[状态集](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)之前的平台早期，这是一个技巧，可以用来确保在任何给定节点上只运行一个类型的容器。例如，我曾经使用它来实现一个elasticsearch集群，方法是将HostPort设置为9200，并指定与节点相同数量的副本。这将被认为是一个可怕的黑客攻击，除非您正在实现一个kubernetes系统组件，否则您不太可能需要主机端口集。

在kubernetes的情况下，第二个特性更加奇怪，这就是pod的主机网络属性。当设置为true时，这与`**——network=host**`参数对`**docker run**`的作用相同。它使pod中的所有容器都使用节点的网络名称空间，即它们都可以访问`**eth0**`并直接在这个接口上打开端口。我认为这不是一个延伸，建议你永远，永远不需要这样做。如果您对此有一个用例，那么您很可能已经是kubernetes的贡献者，不需要我的任何帮助。

# 总结

以上就是kubernetes network系列文章的全部内容。我很喜欢学习和使用这个平台，我希望这些文章能体现我的热情。我认为kubernetes预示着一场革命，它使我们能够可靠地管理和互连集装箱船队，而不是服务器船队。从很多方面来说，它确实是一个装在瓶子里的数据中心，所以它有相当多的潜在复杂性也就不足为奇了。我之所以写这些帖子，是因为我认为，一旦你了解了每一篇文章的工作原理，你就会以一种相当优雅的方式理解它。希望我为平台未来的新用户提供了更容易的入口。