# Kubernetes 网络如何进行工作（第三部分）

原文链接：<https://www.level-up.one/kubernetes-networking-3-level-up/>

原文作者：[James Lee](https://www.level-up.one/author/jameslee/) 

欢迎阅读Kubernetes网络系列文章的第三部分(也是最后一部分)。第一部分和第二部分已经完成了，新手请先第一部分和第二部分，从而更好地了解Kubernetes的网络。相信我，这不会花很多时间，但一定会对你有很大帮助。

和上次一样，让我们先回顾前面的文章中涉及的一些重要内容。在第一部分中，我们介绍了网络支持pod进行连接。这些pod彼此连接，也与Kubernetes集群中的节点连接。在第二部分中，我们介绍了服务网络以及服务网络促进pod负载平衡的方式，从而理解了集群内的客户机能够以高效、可靠的方式与服务网络通信的原因。在本文中，我们将使用第一篇和第二篇文章中的概念，向你展示驻留在集群外部的客户机如何使用相同的网络连接到集群内部的pod。本文将使用很多第一部分和第二部分中的概念。因此，我再次建议你先阅读前两篇文章。

在正文开始之前，请允许我表达我对Kubernetes的赞美。

Kubernetes是一个迅速成熟的平台，它正在改进，并且正在被广泛使用。为什么这样形容Kubernetes？因为我为它感到骄傲。从Kubecon事件你就可以知道Kubernetes是多么有价值！Kubernetes架构中的大多数都是插件，包括网络！例如谷歌的Kubernetes引擎，简直太棒了。我没有机会使用亚马逊的Elastic Kubernetes服务，但我相信它一定也不错。

Kubernetes有自己处理网络问题的独一无二的标准方法。在考虑统一服务网格等替代方案时，请记住这件事。好了各位，请准备好。

下面我们就进入主题。

![](https://github.com/wangzhiji/news.caas.one/blob/master/translation/images/3.01.jpg)

### 路由和负载平衡是否相等

首先，你认为路由和负载平衡是否相等?

当然不相等。在上一篇文章中，我们使用一些pod创建了一个部署，有一个服务被分配了一个IP地址，它被称为“集群IP”，我们向集群IP发送了针对pod的请求。你还记得吗？希望答案是肯定的。现在我们将继续讨论同一个例子：集群IP地址为10.3.241.152，它位于与pod网络不同的IP地址范围内，并且它与节点所在的网络不同，我们知道集群IP所在的这个地址空间叫服务网络。

上一篇文章中我提到过，服务网络完全按照路由规则工作，它没有连接的设备，也不需要接口。请看下图，在图中我们可以看到Kubernetes组件(称为Kube-proxy)如何实现网络：它与称为Netfilter的Linux内核模块协作，用于接收和路由发送到集群IP的流量。但为什么要改变路线呢?因为数据应该被送到正确的Pod里。

![](https://github.com/wangzhiji/news.caas.one/blob/master/translation/images/3.02.png)

图片来源: <https://cdn-images-1.medium.com/max/800/1*Ow5A6_zjjwdKkf2Yi1KgYw.png>

到目前为止，我们已经讨论了连接、请求和数据。要理解Ingress是如何以这种方式工作、更重要的是它为什么以这种方式工作，我们需要更加具体的讨论。

连接和请求受OSI第4层(TCP)或第7层(http、RPC等)的管理。而Netfilter规则基本上是路由规则。它们对第3层的IP数据包进行操作。那么路由决策是如何做出的？所有路由器（包括Netfilter）都根据包中的信息进行路由决策，包中的主要信息是则是”数据包从哪里来，要去哪里?“现在，我们要注意一下基于包中信息发生的的行为。我们可以把它分成三层。首先，每个数据包由10.3.241.152:80发送给服务。它将会到达节点的eth0接口，并通过Netfilter进行处理，而其规则会与服务建立的规则相匹配，然后转发到某个IP地址。

转发到哪个IP地址呢?转发到一些正确的Pod的地址。

外部客户机使用相同的路由基础设施来调用我们的pod，这意味着外部客户机将调用集群IP和端口。为什么?因为集群IP和端口是所有机器的前台。这台机器使我们有可能在任何时候都不关心pod在哪里运行。但集群IP只能从节点的以太网接口访问，在集群之外，没有人知道如何处理这个范围内的地址。所以问题是，我们如何在这种情况下转发数据？从公开可见的IP端点到只有在包已经位于节点上时才可见的IP端点 ?解决方案是什么?

也许你可以使用IP Tables实用程序检查Netfilter规则。通过这样做，你会发现一些令人惊讶的事情：示例服务的规则不限于特定的原始网络！因此，现在如果有来自任何地方的数据包到达节点的以太网接口，其目标地址为10.3.241.152:80，那么它将被匹配并路由到pod。那么，给客户端集群IP是合法的吗?我们能给它分配一些友好的域名吗?然后也许添加一个路由就能使这些包到达到其中一个节点?

请看下图:

![](https://github.com/wangzhiji/news.caas.one/blob/master/translation/images/3.03.png)

图片来源: <https://cdn-images-1.medium.com/max/800/1*skurXk737KHhzbXPbV-Xcg.png>

让我们跟踪这个过程。首先，客户机调用集群IP。然后，数据包遵循到节点的路径。接着，这些包被转发到一个pod。在这种情况下，你可能想要完成这个过程。但这不是个好主意。

而且其后果是严重的。

为什么我会这样说?节点像Pod一样是短暂的，但又不像Pod那么短暂。它们可以迁移到一些新的虚拟机。在那里，集群可以上下伸缩等等。但是，请记住路由是在第3层数据包上操作的。他们不知道健康和不健康服务的区别。是的，但他们确实希望下一步是稳定和可用的。但不幸的是，如果节点变得不可访问，路由将中断并在相当长一段时间内保持中断状态。这种情况经常发生。即使路由是持久的，但所有外部通信都终将通过某一个节点。所以这并不是最优解。

但我们还是需要传递客户端的数据。因此，我们这种并不依赖于集群中特定节点的健康状况的方式并不可行，在这种情况下，没有活动管理，路由就没有任何用处。这不会让我们想出一个可靠的解决方案。那么什么是主动管理呢?例如，Kube-proxy在管理Netfilter中的角色是一个活动管理。将Kubernetes的职责扩展到一些外部路由器的管理是毫无意义的。最重要的是，我们已经有了经过验证的工具可以将客户机流量分配到一组机器上，它们被称为负载平衡器，也是我们针对Kubernetes入侵的解决方案。它能以一种持久的方式工作。

因此，我们需要一个公共IP来使用负载均衡器将客户机流量分配到集群中的节点。客户端可以连接到公共IP。我们还需要负载均衡器将请求转发到的节点上的地址。单靠服务网络(集群IP)不足以在网关路由器和节点之间轻松创建稳定的静态路由。其他可用地址位于以太网地址所连接的网络上。在我们的示例中，网络地址是10.100.0.0/24。网关路由器知道如何将数据包发送到这些接口。从负载均衡器发送到路由器的连接将到达正确的位置。但是假设客户机想要在端口80上连接到我们的服务，我们不能简单地将数据包发送到节点接口上的端口。

请看下图:

![](https://github.com/wangzhiji/news.caas.one/blob/master/translation/images/3.04.png)

图片来源: <https://cdn-images-1.medium.com/max/800/1*I03T4FnCjlPmHNXhao4arg.png>

但为什么会失败呢？你可以注意到在10.100.0.3:80上没有进程监听。Netfilter规则拦截我们的请求，并将其指向与目标地址不匹配的pod。唯一匹配的是服务网络上10.3.241.152:80的集群IP。因此，数据包到达接口时不会被传递。内核以“econndenied”响应。所以现在的情况非常复杂。

首先，Netfilter为转发数据包而建立的网络不容易从网关路由到节点。其次，容易路由的网络不是Netfilter转发数据包的网络。所以现在一切都有点困难。但是还是有一个解决方案：在这些网络之间架起一座桥。你知道了吗，Kubernetes可以帮助我们做一些被称为NodePort的事情。那是什么呢?让我们找出答案吧!

### **savior** NodePort服务

我们创建的示例服务没有指定类型。因此，我们把它当成默认类型ClusterIP。但是还有其他类型的服务可以创建额外的功能，对我们来说重要的是NodePort类型。看一下这个例子：

```
kind: Service
apiVersion: v1
metadata:
  name: service-demo
spec:
  type: NodePort
  selector:
    app: service_demo_pod
  ports:
  - port: 80
    targetPort: http
```

在此代码中，NodePort类型的服务是集群IP服务,服务的名称是service-demo。该服务具有到达节点的IP地址以及指定集群IP地址的附加功能。这是怎样实现的？Kubernetes创建一个名为Kube-proxy的节点服务，它分配一个范围为30000-32767的端口，并在每个节点的eth0接口上打开端口。这也是它被称为NodePort的原因。这个pod直接连接服务集群。我们可以创建上面的服务，然后运行Kubectl get svc service-demo。它将帮助我们查看已分配的节点。

下面是命令:

```
$ kubectl get svc service-demo

NAME:                   CLUSTER-IP       EXTERNAL-IP      PORT(S)

service-demo      10.3.241.152         <none>                    80:32213/TCP
```

在这个例子中，我们的服务被分配到NodePort 32213。因此，我们可以连接到集群中任意一个节点上的服务，即10.100.0.2:32213或10.100.0.3:32213。数据将被转发到服务。因此，现在我们有了一个完整的管道来平衡外部客户机请求到集群中所有节点的负载。

![](https://github.com/wangzhiji/news.caas.one/blob/master/translation/images/3.05.png)

图片来源:<https://cdn-images-1.medium.com/max/800/1*Uo_wGCIlFopJZbf6THu0OQ.png>

从上面共享的映像中，我们可以看到客户机通过一个公共IP地址连接到负载均衡器。负载均衡器选择一个节点，并将其连接到地址为10.100.0.3:32213的节点。 Kube-proxy接收此连接并将其转发到集群IP 10.3.241.152:80上的服务。此时，再请求匹配Netfilter规则将被重定向到10.0.2.2:8080上的服务器pod。这看起来有点复杂，但我们必须这样做。

虽让这个办法也存在一些问题。

当你使用NodePorts时，它会在一些非标准端口上间接地向客户端公开你的服务。虽然负载平衡器公开是普通的端口而不是节点端口，但在一些场景下，比如谷歌云上的内部负载均衡器，节点端口会向上游传播。此外，节点是有限的资源，而且在请求中保存源IP也有一些限制。

所以NodePorts并不是完整的解决方案。他们在集群前面需要某种负载均衡器。因此，这种需求导致了从Kubernetes中指定负载均衡器配置的两种不同方式。下面我们开始讨论负载均衡器（Load Balancer）的相关内容。

### LoadBalancer服务和入侵资源的出现

外部通信可以通过一个节点到达集群。我们在上一篇文章中已经讨论过了，此时平台设计师可以选择组织这个过程。但这会给你带来麻烦！那么公共ip和负载均衡器呢？因此，在支持API驱动的网络资源配置的环境中，Kubernetes使在一个地方定义所有内容成为可能。LoadBalancer是一个简单的服务，它具有节点服务的所有功能，可以构建良好的入口路径。我假设你正在运行的环境类似于GCP或AWS，后者支持API驱动的配置。

请看代码:

```
kind: Service
apiVersion: v1
metadata:
name: service-demo
spec:
type: LoadBalancer
selector:
app: service_demo_pod
ports:
- port: 80
targetPort: http
```

假设我们在谷歌Kubernetes引擎上删除并重新创建示例服务,运行Kubectl命令将产生什么结果?

我们可以试一试。

```
$ kubectl get svc service-demo

NAME           CLUSTER-IP        EXTERNAL-IP PORT(S)                AGE

openvpn       10.3.241.52           35.184.97.156 80:32213/TCP        5m
```

分配外部IP可能需要一些时间，大概几分钟，这取决于资源的数量。在GCP上有一些不同。首先，创建一个外部IP、一个转发规则、一个目标代理、一个后端服务，可能还需要一个实例组。IP分配完成后，可以使用上述所有方法连接服务。域名也被分配给客户端。

但是LoadBalancer类型的服务也有一些限制。它无法配置ID来终止https数据，也无法实现虚拟主机和基于路径的路由。因此，一个LoadBalancer不足以代理多个服务。所有这些导致在1.2版中添加了一个用于配置LoadBalancer的独立Kubernetes资源，它被称为入口。LoadBalancer扩展了单个服务来支持外部客户端，而Ingress提供了一个独立的资源来灵活配置LoadBalancer。Ingress API支持TLS终止、虚拟主机和基于路径的路由。因此，它可以设置一个LoadBalancer来处理多个后端服务。

想实现一个遵循Kubernetes的基本模式，要有一个资源类型和一个控制器用于管理该类型。这里，资源是Ingress.，它包括对网络资源的请求。

让我们看一下测试服务的入口资源。

```
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
name: demo-ingress
annotations:
kubernetes.io/ingress.class: "gce"
spec:
tls:
- secretName: my-ssl-secret
rules:
- host: testhost.com
http:
paths:
- path: /*
backend:
serviceName: service-demo
servicePort: 80
```

入口控制器通过在必要的状态环境中驱动资源来满足请求。使用Ingress，你可以将服务创建为NodePort类型。创建之后，Ingress控制器负责接收和将数据引导到节点。但是请理解，混合进入资源和LoadBalancer服务可能会导致一些微妙的问题。这取决于环境。

### 主机端口和主机网络

HostPort是容器的属性，它在ContainerPort结构中声明。如果将其设置为给定的端口号，则会导致在节点上打开端口，然后它会被直接转发到容器，不需要代理。而端口只对容器运行的节点开放。

下一个属性称为pod的主机网络，如果将其设置为true，则其效果与docker run的network=host参数类似。pod中的所有容器都使用节点的网络名称空间，它们可以访问eth0并直接打开端口。当然，很可能你永远都不需要这个。但如果您已经有了这个用例，那么我向您致敬！这意味着您已经是Kubernetes的贡献者了。

### 结论

这就是Kubernetes系列文章的最后一部分。Kubernetes平台是一个非常棒的平台，我喜欢它的每一点。通过实践、工作和教学，我也学到了很多关于它。就我个人而言，我认为Kubernetes是一场革命，它使得可靠地管理和连接大型容器组成为可能。

Kubernetes前途无量，而且必将日益成熟。通过本系列文章，我希望每个人都能更多地了解Kubernetes。相信我，你知道的越多，你就越会爱上Kubernetes!感谢您对本文的支持和阅读。

这是Kubernetes Bible的链接，现在开始学习基础知识：

[Kubernetes初学者和开发者手册](https://www.level-up.one/kubernetes-bible-beginners/)

这里是Kubernetes视频教程的链接：

[从DevOps大师的视频课程中学习Kubernetes](https://academy.level-up.one/p/learn-kubernetes-from-a-devops-guru-kubernetes-docker/?product_id=698613&coupon_code=BLOG_K8S_NETWORK_1)